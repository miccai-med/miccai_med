{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83e\udec1 PneuNet - Chest X-ray Multi-Label Classification\n",
        "\n",
        "**Dataset:** CheXpert 3-class (Cardiomegaly, Edema, Pneumothorax) - No Finding Excluded\n",
        "\n",
        "**Model:** PneuNet (ResNet-18 + Transformer Encoder)\n",
        "\n",
        "**Architecture:**\n",
        "- ResNet-18 backbone for feature extraction\n",
        "- Transformer encoder for spatial reasoning (6 layers, 8 heads)\n",
        "- Deep MLP classifier\n",
        "\n",
        "**Outputs:**\n",
        "- 3 Binary Classification Reports (one per class)\n",
        "- 3 Binary Confusion Matrices (one per class)\n",
        "- Training/Validation Loss & Accuracy Curves\n",
        "- ROC Curves for all 3 classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "# Torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "# Sklearn metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix, \n",
        "    roc_curve, auc, accuracy_score, f1_score,\n",
        "    precision_score, recall_score\n",
        ")\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u2699\ufe0f Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Config:\n",
        "    # Paths - UPDATE THIS TO YOUR DATASET NAME\n",
        "    DATA_DIR = \"/kaggle/input/chest-xray-4class-100k\"  # Your uploaded dataset\n",
        "    OUTPUT_DIR = \"/kaggle/working\"\n",
        "    \n",
        "    # Model\n",
        "    MODEL_NAME = \"pneunet\"\n",
        "    NUM_CLASSES = 3\n",
        "    LABELS = [\"Cardiomegaly\", \"Edema\", \"Pneumothorax\"]\n",
        "    \n",
        "    # PneuNet specific\n",
        "    FREEZE_BACKBONE = False  # Set to True to freeze ResNet backbone\n",
        "    INPUT_CHANNELS = 3  # RGB images\n",
        "    USE_80_TOKENS = True  # True for 10x8 tokens, False for 7x7 tokens\n",
        "    \n",
        "    # Training\n",
        "    BATCH_SIZE = 32\n",
        "    NUM_EPOCHS = 25\n",
        "    LEARNING_RATE = 1e-4\n",
        "    WEIGHT_DECAY = 1e-5\n",
        "    \n",
        "    # Image\n",
        "    IMG_SIZE = 224\n",
        "    \n",
        "    # Device\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    # Random seed\n",
        "    SEED = 42\n",
        "\n",
        "config = Config()\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "def set_seed(seed):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(config.SEED)\n",
        "\n",
        "print(f\"\ud83d\udda5\ufe0f Device: {config.DEVICE}\")\n",
        "print(f\"\ud83e\udd16 Model: {config.MODEL_NAME}\")\n",
        "print(f\"\ud83c\udff7\ufe0f Labels: {config.LABELS}\")\n",
        "print(f\"\ud83d\udd27 Tokens: {'80 (10x8)' if config.USE_80_TOKENS else '49 (7x7)'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udce6 Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ChestXrayDataset(Dataset):\n",
        "    def __init__(self, dataframe, data_dir, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.labels = config.LABELS\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        row = self.dataframe.iloc[idx]\n",
        "        img_path = os.path.join(self.data_dir, row['new_path'])\n",
        "        \n",
        "        # Load image\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        \n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        # Get multi-label target\n",
        "        label = torch.FloatTensor([row[label] for label in self.labels])\n",
        "        \n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83c\udfa8 Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((config.IMG_SIZE, config.IMG_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((config.IMG_SIZE, config.IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcca Load CheXpert Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metadata_path = os.path.join(config.DATA_DIR, 'metadata.csv')\n",
        "\n",
        "if os.path.exists(metadata_path):\n",
        "    df = pd.read_csv(metadata_path)\n",
        "    print(f\"\ud83d\udcc1 Total samples: {len(df)}\")\n",
        "    print(f\"\\n\ud83d\udccb Label distribution:\")\n",
        "    for label in config.LABELS:\n",
        "        if label in df.columns:\n",
        "            count = (df[label] == 1.0).sum()\n",
        "            print(f\"  {label}: {count} ({count/len(df)*100:.2f}%)\")\n",
        "else:\n",
        "    print(\"\u26a0\ufe0f Metadata file not found. Creating dummy data structure for compilation check.\")\n",
        "    df = pd.DataFrame(columns=['new_path'] + config.LABELS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data\n",
        "if len(df) > 0:\n",
        "    train_df, val_df = train_test_split(\n",
        "        df, test_size=0.2, random_state=config.SEED, \n",
        "        stratify=None\n",
        "    )\n",
        "else:\n",
        "    train_df, val_df = df, df\n",
        "\n",
        "print(f\"\ud83c\udfcb\ufe0f Train samples: {len(train_df)}\")\n",
        "print(f\"\ud83e\uddea Validation samples: {len(val_df)}\")\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = ChestXrayDataset(train_df, config.DATA_DIR, train_transform)\n",
        "val_dataset = ChestXrayDataset(val_df, config.DATA_DIR, val_transform)\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, \n",
        "    batch_size=config.BATCH_SIZE, \n",
        "    shuffle=True, \n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset, \n",
        "    batch_size=config.BATCH_SIZE, \n",
        "    shuffle=False, \n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(f\"\\n\u2705 DataLoaders created!\")\n",
        "print(f\"   Train batches: {len(train_loader)}\")\n",
        "print(f\"   Val batches: {len(val_loader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83e\udd16 PneuNet Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PneuNet(nn.Module):\n",
        "    def __init__(self, num_classes=3, freeze_backbone=False, input_channels=3, use_80_tokens=True):\n",
        "        \"\"\"\n",
        "        PneuNet: ResNet-18 + Transformer Encoder for medical image classification\n",
        "        \n",
        "        Parameters:\n",
        "          - num_classes (int): Number of output classes.\n",
        "          - freeze_backbone (bool): If True, freeze ResNet backbone parameters.\n",
        "          - input_channels (int): Number of channels in input images (1 for grayscale, 3 for RGB).\n",
        "          - use_80_tokens (bool): If True, use 10x8 tokens; otherwise, use 7x7 tokens.\n",
        "        \"\"\"\n",
        "        super(PneuNet, self).__init__()\n",
        "        \n",
        "        # Load pretrained ResNet-18 backbone\n",
        "        resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "        \n",
        "        # Modify first conv layer if input channels != 3\n",
        "        if input_channels != 3:\n",
        "            resnet.conv1 = nn.Conv2d(input_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        \n",
        "        # Truncate ResNet to get spatial feature map from layer4\n",
        "        self.backbone = nn.Sequential(\n",
        "            resnet.conv1,\n",
        "            resnet.bn1,\n",
        "            resnet.relu,\n",
        "            resnet.maxpool,\n",
        "            resnet.layer1,\n",
        "            resnet.layer2,\n",
        "            resnet.layer3,\n",
        "            resnet.layer4,  # output: [b, 512, 7, 7]\n",
        "        )\n",
        "        \n",
        "        # Optionally freeze backbone\n",
        "        if freeze_backbone:\n",
        "            for param in self.backbone.parameters():\n",
        "                param.requires_grad = False\n",
        "        \n",
        "        # BatchNorm after backbone\n",
        "        self.post_resnet_bn = nn.BatchNorm2d(512)\n",
        "        \n",
        "        # Adaptive pooling for token configuration\n",
        "        if use_80_tokens:\n",
        "            self.adaptive_pool = nn.AdaptiveAvgPool2d((10, 8))\n",
        "        else:\n",
        "            self.adaptive_pool = nn.Identity()\n",
        "        \n",
        "        # Transformer Encoder\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=512,\n",
        "            nhead=8,\n",
        "            dim_feedforward=2048,\n",
        "            dropout=0.1,\n",
        "            activation='relu',\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)\n",
        "        \n",
        "        # Layer Normalization\n",
        "        self.layer_norm = nn.LayerNorm(512)\n",
        "        \n",
        "        # Determine number of tokens\n",
        "        token_count = 10 * 8 if use_80_tokens else 7 * 7\n",
        "        \n",
        "        # MLP Classifier\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(token_count * 512, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1024, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(64, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(16, num_classes)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Extract features with ResNet\n",
        "        features = self.backbone(x)  # [b, 512, 7, 7]\n",
        "        \n",
        "        # Apply BatchNorm\n",
        "        features = self.post_resnet_bn(features)\n",
        "        \n",
        "        # Adapt spatial dimensions\n",
        "        features = self.adaptive_pool(features)\n",
        "        \n",
        "        # Reshape to sequence for Transformer\n",
        "        b, c, h, w = features.shape\n",
        "        features = features.view(b, c, h * w).permute(0, 2, 1)  # [b, tokens, 512]\n",
        "        \n",
        "        # Transformer encoding\n",
        "        transformed = self.transformer_encoder(features)\n",
        "        \n",
        "        # Layer normalization\n",
        "        transformed = self.layer_norm(transformed)\n",
        "        \n",
        "        # Flatten for MLP\n",
        "        transformed = transformed.view(b, -1)\n",
        "        \n",
        "        # Classification\n",
        "        out = self.mlp(transformed)\n",
        "        return out\n",
        "\n",
        "# Create model\n",
        "model = PneuNet(\n",
        "    num_classes=config.NUM_CLASSES,\n",
        "    freeze_backbone=config.FREEZE_BACKBONE,\n",
        "    input_channels=config.INPUT_CHANNELS,\n",
        "    use_80_tokens=config.USE_80_TOKENS\n",
        ")\n",
        "model = model.to(config.DEVICE)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"\ud83d\udcca Total parameters: {total_params:,}\")\n",
        "print(f\"\ud83d\udcca Trainable parameters: {trainable_params:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83c\udfaf Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loss function, optimizer, scheduler\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=config.LEARNING_RATE, weight_decay=config.WEIGHT_DECAY)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=config.NUM_EPOCHS, eta_min=1e-6)\n",
        "\n",
        "print(\"\u2705 Training setup complete!\")\n",
        "print(f\"  Loss: BCEWithLogitsLoss\")\n",
        "print(f\"  Optimizer: AdamW (lr={config.LEARNING_RATE})\")\n",
        "print(f\"  Scheduler: CosineAnnealingLR\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udd04 Training & Validation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_epoch(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    \n",
        "    for images, labels in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        all_preds.append(torch.sigmoid(outputs).detach().cpu())\n",
        "        all_labels.append(labels.cpu())\n",
        "    \n",
        "    avg_loss = running_loss / len(loader)\n",
        "    all_preds = torch.cat(all_preds)\n",
        "    all_labels = torch.cat(all_labels)\n",
        "    accuracy = ((all_preds > 0.5) == all_labels).float().mean().item()\n",
        "    \n",
        "    return avg_loss, accuracy\n",
        "\n",
        "def validate_epoch(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            \n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            all_preds.append(torch.sigmoid(outputs).cpu())\n",
        "            all_labels.append(labels.cpu())\n",
        "    \n",
        "    avg_loss = running_loss / len(loader)\n",
        "    all_preds = torch.cat(all_preds)\n",
        "    all_labels = torch.cat(all_labels)\n",
        "    accuracy = ((all_preds > 0.5) == all_labels).float().mean().item()\n",
        "    \n",
        "    return avg_loss, accuracy, all_preds, all_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\ude80 Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = {\n",
        "    'train_loss': [],\n",
        "    'train_acc': [],\n",
        "    'val_loss': [],\n",
        "    'val_acc': []\n",
        "}\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "best_model_path = os.path.join(config.OUTPUT_DIR, 'pneunet_chestxray.pth')\n",
        "\n",
        "print(\"\ud83c\udfcb\ufe0f Starting training...\\n\")\n",
        "\n",
        "for epoch in range(config.NUM_EPOCHS):\n",
        "    print(f\"Epoch {epoch+1}/{config.NUM_EPOCHS}\")\n",
        "    \n",
        "    # Train\n",
        "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, config.DEVICE)\n",
        "    \n",
        "    # Validate\n",
        "    val_loss, val_acc, val_preds, val_labels = validate_epoch(model, val_loader, criterion, config.DEVICE)\n",
        "    \n",
        "    # Update scheduler\n",
        "    scheduler.step()\n",
        "    \n",
        "    # Store history\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['val_acc'].append(val_acc)\n",
        "    \n",
        "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
        "    print(f\"  Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "    print(f\"  LR: {optimizer.param_groups[0]['lr']:.6f}\\n\")\n",
        "    \n",
        "    # Save best model\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'val_loss': val_loss,\n",
        "            'val_acc': val_acc\n",
        "        }, best_model_path)\n",
        "        print(f\"  \ud83d\udcbe Saved best model (val_loss: {val_loss:.4f})\\n\")\n",
        "\n",
        "print(\"\u2705 Training complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcc8 Training Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Loss\n",
        "axes[0].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
        "axes[0].plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
        "axes[0].set_xlabel('Epoch', fontsize=12)\n",
        "axes[0].set_ylabel('Loss', fontsize=12)\n",
        "axes[0].set_title('Training & Validation Loss', fontsize=14, fontweight='bold')\n",
        "axes[0].legend(fontsize=11)\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Accuracy\n",
        "axes[1].plot(history['train_acc'], label='Train Accuracy', linewidth=2)\n",
        "axes[1].plot(history['val_acc'], label='Val Accuracy', linewidth=2)\n",
        "axes[1].set_xlabel('Epoch', fontsize=12)\n",
        "axes[1].set_ylabel('Accuracy', fontsize=12)\n",
        "axes[1].set_title('Training & Validation Accuracy', fontsize=14, fontweight='bold')\n",
        "axes[1].legend(fontsize=11)\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(config.OUTPUT_DIR, 'pneunet_training_curves.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(\"\u2705 Saved: pneunet_training_curves.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcca Evaluation - Load Best Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load best model\n",
        "checkpoint = torch.load(best_model_path)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "print(f\"\u2705 Loaded best model from epoch {checkpoint['epoch']}\")\n",
        "print(f\"   Val Loss: {checkpoint['val_loss']:.4f}\")\n",
        "print(f\"   Val Acc: {checkpoint['val_acc']:.4f}\")\n",
        "\n",
        "# Get predictions\n",
        "_, val_acc, all_probs, all_labels = validate_epoch(model, val_loader, criterion, config.DEVICE)\n",
        "all_preds = (all_probs > 0.5).float()\n",
        "\n",
        "all_preds = all_preds.numpy()\n",
        "all_probs = all_probs.numpy()\n",
        "all_labels = all_labels.numpy()\n",
        "\n",
        "print(f\"\\n\ud83d\udcca Predictions shape: {all_preds.shape}\")\n",
        "print(f\"\ud83d\udcca Labels shape: {all_labels.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udccb Per-Class Classification Reports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reports_data = []\n",
        "\n",
        "for i, label in enumerate(config.LABELS):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"\ud83d\udcca {label}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    y_true = all_labels[:, i]\n",
        "    y_pred = all_preds[:, i]\n",
        "    \n",
        "    # Classification report\n",
        "    report = classification_report(y_true, y_pred, target_names=['Negative', 'Positive'], output_dict=True)\n",
        "    print(classification_report(y_true, y_pred, target_names=['Negative', 'Positive']))\n",
        "    \n",
        "    # Calculate metrics\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    \n",
        "    reports_data.append({\n",
        "        'Label': label,\n",
        "        'Accuracy': acc,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1-Score': f1\n",
        "    })\n",
        "\n",
        "# Save to CSV\n",
        "reports_df = pd.DataFrame(reports_data)\n",
        "reports_df.to_csv(os.path.join(config.OUTPUT_DIR, 'pneunet_classification_reports.csv'), index=False)\n",
        "print(f\"\\n\u2705 Saved: pneunet_classification_reports.csv\")\n",
        "print(f\"\\n{reports_df}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udd32 Confusion Matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "colors = ['#e74c3c', '#3498db', '#2ecc71']\n",
        "\n",
        "for i, label in enumerate(config.LABELS):\n",
        "    y_true = all_labels[:, i]\n",
        "    y_pred = all_preds[:, i]\n",
        "    \n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    \n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "                xticklabels=['Negative', 'Positive'],\n",
        "                yticklabels=['Negative', 'Positive'],\n",
        "                ax=axes[i], cbar=True, square=True)\n",
        "    \n",
        "    axes[i].set_xlabel('Predicted', fontsize=11)\n",
        "    axes[i].set_ylabel('Actual', fontsize=11)\n",
        "    axes[i].set_title(f'\ud83c\udff7\ufe0f {label}', fontsize=13, fontweight='bold', color=colors[i])\n",
        "\n",
        "plt.suptitle('PneuNet - Confusion Matrices', fontsize=16, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(config.OUTPUT_DIR, 'pneunet_confusion_matrices.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(\"\u2705 Saved: pneunet_confusion_matrices.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcca Metrics Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "colors = ['#e74c3c', '#3498db', '#2ecc71']\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "\n",
        "for i, label in enumerate(config.LABELS):\n",
        "    values = reports_df[reports_df['Label'] == label][metrics].values[0]\n",
        "    \n",
        "    bars = axes[i].bar(metrics, values, color=colors[i], alpha=0.7, edgecolor='black')\n",
        "    axes[i].set_ylim([0, 1])\n",
        "    axes[i].set_ylabel('Score', fontsize=11)\n",
        "    axes[i].set_title(f'\ud83c\udff7\ufe0f {label}', fontsize=13, fontweight='bold')\n",
        "    axes[i].grid(True, axis='y', alpha=0.3)\n",
        "    \n",
        "    # Add value labels on bars\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        axes[i].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                    f'{height:.3f}', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "plt.suptitle('PneuNet - Metrics Comparison', fontsize=16, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(config.OUTPUT_DIR, 'pneunet_metrics_comparison.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(\"\u2705 Saved: pneunet_metrics_comparison.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcc8 ROC Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(all_preds) > 0:\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "    colors = ['#e74c3c', '#3498db', '#2ecc71']\n",
        "\n",
        "    for i, label in enumerate(config.LABELS):\n",
        "        class_probs = all_probs[:, i]\n",
        "        class_labels = all_labels[:, i]\n",
        "        \n",
        "        # Compute ROC curve\n",
        "        fpr, tpr, _ = roc_curve(class_labels, class_probs)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        \n",
        "        # Plot\n",
        "        axes[i].plot(fpr, tpr, color=colors[i], linewidth=2, \n",
        "                     label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
        "        axes[i].plot([0, 1], [0, 1], 'k--', linewidth=1, alpha=0.5)\n",
        "        axes[i].fill_between(fpr, tpr, alpha=0.2, color=colors[i])\n",
        "        axes[i].set_xlim([0.0, 1.0])\n",
        "        axes[i].set_ylim([0.0, 1.05])\n",
        "        axes[i].set_xlabel('False Positive Rate', fontsize=12)\n",
        "        axes[i].set_ylabel('True Positive Rate', fontsize=12)\n",
        "        axes[i].set_title(f'\ud83c\udff7\ufe0f {label}\\nROC Curve', fontsize=14, fontweight='bold')\n",
        "        axes[i].legend(loc='lower right', fontsize=11)\n",
        "        axes[i].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.suptitle('PneuNet - ROC Curves', fontsize=16, fontweight='bold', y=1.02)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(config.OUTPUT_DIR, 'pneunet_roc_curves.png'), dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"\u2705 Saved: pneunet_roc_curves.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83c\udf89 Final Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"\ud83c\udf89 TRAINING COMPLETE! - PneuNet\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if len(all_preds) > 0:\n",
        "    print(f\"\"\"\n",
        "    \ud83e\udd16 Model: PneuNet (ResNet-18 + Transformer)\n",
        "    \ud83d\udcca Dataset: CheXpert (3-class: {', '.join(config.LABELS)})\n",
        "    \ud83c\udfcb\ufe0f Training samples: {len(train_df)}\n",
        "    \ud83e\uddea Validation samples: {len(val_df)}\n",
        "\n",
        "    \ud83d\udcc9 Best Validation Loss: {best_val_loss:.4f}\n",
        "    \ud83d\udcc8 Final Validation Accuracy: {val_acc:.4f}\n",
        "\n",
        "    \ud83d\udcc1 Output Files:\n",
        "      \ud83d\udcca pneunet_training_curves.png\n",
        "      \ud83d\udcca pneunet_confusion_matrices.png\n",
        "      \ud83d\udcca pneunet_metrics_comparison.png\n",
        "      \ud83d\udcca pneunet_roc_curves.png\n",
        "      \ud83d\udcc4 pneunet_classification_reports.csv\n",
        "      \ud83d\udd27 pneunet_chestxray.pth\n",
        "\n",
        "    \ud83d\udccb Per-Class Performance:\n",
        "    \"\"\")\n",
        "\n",
        "    for _, row in reports_df.iterrows():\n",
        "        print(f\"  {row['Label']}: Acc={row['Accuracy']:.4f} | F1={row['F1-Score']:.4f}\")\n",
        "\n",
        "    print(\"\\n\u2705 All outputs saved successfully!\")\n",
        "else:\n",
        "    print(\"\u26a0\ufe0f No results to report.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}