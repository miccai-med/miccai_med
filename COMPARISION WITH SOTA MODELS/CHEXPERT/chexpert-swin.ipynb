{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":14711207,"datasetId":9399080,"databundleVersionId":15556955}],"dockerImageVersionId":31287,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":9426.064159,"end_time":"2026-02-03T04:08:39.380522","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2026-02-03T01:31:33.316363","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"427d7da3","cell_type":"markdown","source":"# ğŸ« MobileNet V2 - Chest X-ray Multi-Label Classification\n\n**Dataset:** CheXpert 3-class (Cardiomegaly, Edema, Pneumothorax) - No Finding Excluded\n\n**Model:** MobileNet V2 (pretrained on ImageNet)\n\n**Outputs:**\n- 3 Binary Classification Reports (one per class)\n- 3 Binary Confusion Matrices (one per class)\n- Training/Validation Loss & Accuracy Curves\n- ROC Curves for all 3 classes","metadata":{"papermill":{"duration":0.005048,"end_time":"2026-02-03T01:31:35.939136","exception":false,"start_time":"2026-02-03T01:31:35.934088","status":"completed"},"tags":[]}},{"id":"5b3009ec","cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# PyTorch\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\n\n# Torchvision\nimport torchvision.transforms as transforms\nfrom torchvision.models import mobilenet_v2, MobileNet_V2_Weights\n\n# Sklearn metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import (\n    classification_report, confusion_matrix, \n    roc_curve, auc, accuracy_score, f1_score,\n    precision_score, recall_score\n)\n\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")","metadata":{"execution":{"iopub.status.busy":"2026-02-21T05:14:20.161999Z","iopub.execute_input":"2026-02-21T05:14:20.163040Z","iopub.status.idle":"2026-02-21T05:14:20.169112Z","shell.execute_reply.started":"2026-02-21T05:14:20.162996Z","shell.execute_reply":"2026-02-21T05:14:20.168434Z"},"papermill":{"duration":12.243593,"end_time":"2026-02-03T01:31:48.186399","exception":false,"start_time":"2026-02-03T01:31:35.942806","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"PyTorch version: 2.9.0+cu126\nCUDA available: True\n","output_type":"stream"}],"execution_count":8},{"id":"b1b43ab0","cell_type":"markdown","source":"## âš™ï¸ Configuration","metadata":{"papermill":{"duration":0.003498,"end_time":"2026-02-03T01:31:48.193863","exception":false,"start_time":"2026-02-03T01:31:48.190365","status":"completed"},"tags":[]}},{"id":"c8fdd7a9-4dee-41c6-8b66-3a0e5399217d","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"41b1df35","cell_type":"code","source":"class Config:\n    # Paths - UPDATE THIS TO YOUR DATASET NAME\n    DATA_DIR = \"/kaggle/input/datasets/shiv28/chest-xray-4class-100k/\"  # Your uploaded dataset\n    OUTPUT_DIR = \"/kaggle/working\"\n    \n    # Model\n    MODEL_NAME = \"mobilenet\"\n    NUM_CLASSES = 3\n    LABELS = [\"Cardiomegaly\", \"Edema\", \"Pneumothorax\"]\n    \n    # Training\n    BATCH_SIZE = 32\n    NUM_EPOCHS = 25\n    LEARNING_RATE = 1e-4\n    WEIGHT_DECAY = 1e-5\n    \n    # Image\n    IMG_SIZE = 224\n    \n    # Device\n    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    # Random seed\n    SEED = 42\n\nconfig = Config()\n\n# Set seeds for reproducibility\ndef set_seed(seed):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(config.SEED)\n\nprint(f\"ğŸ–¥ï¸ Device: {config.DEVICE}\")\nprint(f\"ğŸ¤– Model: {config.MODEL_NAME}\")\nprint(f\"ğŸ·ï¸ Labels: {config.LABELS}\")","metadata":{"execution":{"iopub.status.busy":"2026-02-21T05:14:20.170418Z","iopub.execute_input":"2026-02-21T05:14:20.170687Z","iopub.status.idle":"2026-02-21T05:14:20.182696Z","shell.execute_reply.started":"2026-02-21T05:14:20.170665Z","shell.execute_reply":"2026-02-21T05:14:20.182151Z"},"papermill":{"duration":0.018147,"end_time":"2026-02-03T01:31:48.215555","exception":false,"start_time":"2026-02-03T01:31:48.197408","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"ğŸ–¥ï¸ Device: cuda\nğŸ¤– Model: mobilenet\nğŸ·ï¸ Labels: ['Cardiomegaly', 'Edema', 'Pneumothorax']\n","output_type":"stream"}],"execution_count":9},{"id":"de4aaaaf","cell_type":"markdown","source":"## ğŸ“¦ Dataset Class","metadata":{"papermill":{"duration":0.003625,"end_time":"2026-02-03T01:31:48.222908","exception":false,"start_time":"2026-02-03T01:31:48.219283","status":"completed"},"tags":[]}},{"id":"f03ebd11","cell_type":"code","source":"class ChestXrayDataset(Dataset):\n    def __init__(self, df, img_dir, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.img_dir = img_dir\n        self.transform = transform\n        self.labels = config.LABELS\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        \n        # Get image path\n        img_path = row['new_path']\n        full_path = os.path.join(self.img_dir, img_path)\n        \n        # Load image\n        try:\n            image = Image.open(full_path).convert('RGB')\n        except Exception as e:\n            print(f\"Error loading {full_path}: {e}\")\n            image = Image.new('RGB', (config.IMG_SIZE, config.IMG_SIZE), (0, 0, 0))\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        # Get labels (multi-hot encoding)\n        labels = []\n        for label in self.labels:\n            val = row[label] if label in row.index else 0\n            labels.append(1.0 if val == 1.0 else 0.0)\n        \n        labels = torch.tensor(labels, dtype=torch.float32)\n        \n        return image, labels","metadata":{"execution":{"iopub.status.busy":"2026-02-21T05:14:20.183644Z","iopub.execute_input":"2026-02-21T05:14:20.183993Z","iopub.status.idle":"2026-02-21T05:14:20.195352Z","shell.execute_reply.started":"2026-02-21T05:14:20.183951Z","shell.execute_reply":"2026-02-21T05:14:20.194744Z"},"papermill":{"duration":0.011913,"end_time":"2026-02-03T01:31:48.238431","exception":false,"start_time":"2026-02-03T01:31:48.226518","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":10},{"id":"764309ee","cell_type":"markdown","source":"## ğŸ”„ Data Transforms","metadata":{"papermill":{"duration":0.003662,"end_time":"2026-02-03T01:31:48.245726","exception":false,"start_time":"2026-02-03T01:31:48.242064","status":"completed"},"tags":[]}},{"id":"e888a5de","cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.Resize((config.IMG_SIZE, config.IMG_SIZE)),\n   \n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                        std=[0.229, 0.224, 0.225])\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((config.IMG_SIZE, config.IMG_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                        std=[0.229, 0.224, 0.225])\n])","metadata":{"execution":{"iopub.status.busy":"2026-02-21T05:14:20.196148Z","iopub.execute_input":"2026-02-21T05:14:20.196328Z","iopub.status.idle":"2026-02-21T05:14:20.209706Z","shell.execute_reply.started":"2026-02-21T05:14:20.196313Z","shell.execute_reply":"2026-02-21T05:14:20.209015Z"},"papermill":{"duration":0.011144,"end_time":"2026-02-03T01:31:48.260452","exception":false,"start_time":"2026-02-03T01:31:48.249308","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":11},{"id":"d8190477","cell_type":"markdown","source":"## ğŸ“Š Load Data","metadata":{"papermill":{"duration":0.003768,"end_time":"2026-02-03T01:31:48.268015","exception":false,"start_time":"2026-02-03T01:31:48.264247","status":"completed"},"tags":[]}},{"id":"eace4943","cell_type":"code","source":"print(\"=\" * 60)\nprint(\"LOADING DATA\")\nprint(\"=\" * 60)\n\n# Check what's in the data directory\nprint(f\"\\nContents of {config.DATA_DIR}:\")\nif os.path.exists(config.DATA_DIR):\n    for item in os.listdir(config.DATA_DIR):\n        print(f\"  {item}\")\nelse:\n    print(f\"  âš ï¸ Directory {config.DATA_DIR} not found. Please check dataset path.\")\n\n# Load metadata\nmetadata_path = os.path.join(config.DATA_DIR, \"metadata.csv\")\nif os.path.exists(metadata_path):\n    df = pd.read_csv(metadata_path)\n    print(f\"\\nğŸ“ˆ Total samples: {len(df)}\")\n\n    # Check label distribution\n    print(\"\\nğŸ“Š Label distribution:\")\n    for label in config.LABELS:\n        if label in df.columns:\n            count = (df[label] == 1.0).sum()\n            print(f\"  {label}: {count} ({count/len(df)*100:.2f}%)\")\nelse:\n    # Fallback for testing without data\n    print(\"âš ï¸ Metadata file not found. Creating dummy data structure for compilation check.\")\n    df = pd.DataFrame(columns=['new_path'] + config.LABELS)","metadata":{"execution":{"iopub.status.busy":"2026-02-21T05:14:20.211090Z","iopub.execute_input":"2026-02-21T05:14:20.211305Z","iopub.status.idle":"2026-02-21T05:14:20.495511Z","shell.execute_reply.started":"2026-02-21T05:14:20.211287Z","shell.execute_reply":"2026-02-21T05:14:20.494710Z"},"papermill":{"duration":0.398661,"end_time":"2026-02-03T01:31:48.670373","exception":false,"start_time":"2026-02-03T01:31:48.271712","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"============================================================\nLOADING DATA\n============================================================\n\nContents of /kaggle/input/datasets/shiv28/chest-xray-4class-100k/:\n  images\n  metadata.csv\n\nğŸ“ˆ Total samples: 95060\n\nğŸ“Š Label distribution:\n  Cardiomegaly: 23451 (24.67%)\n  Edema: 49717 (52.30%)\n  Pneumothorax: 17700 (18.62%)\n","output_type":"stream"}],"execution_count":12},{"id":"4b973f65","cell_type":"code","source":"# Split data\nif len(df) > 0:\n    train_df, val_df = train_test_split(\n        df, test_size=0.2, random_state=config.SEED, \n        stratify=None\n    )\nelse:\n    train_df, val_df = df, df\n\nprint(f\"ğŸ‹ï¸ Train samples: {len(train_df)}\")\nprint(f\"ğŸ§ª Validation samples: {len(val_df)}\")\n\n# Create datasets\ntrain_dataset = ChestXrayDataset(train_df, config.DATA_DIR, train_transform)\nval_dataset = ChestXrayDataset(val_df, config.DATA_DIR, val_transform)\n\n# Create dataloaders\ntrain_loader = DataLoader(\n    train_dataset, \n    batch_size=config.BATCH_SIZE, \n    shuffle=True, \n    num_workers=2,\n    pin_memory=True\n)\n\nval_loader = DataLoader(\n    val_dataset, \n    batch_size=config.BATCH_SIZE, \n    shuffle=False, \n    num_workers=2,\n    pin_memory=True\n)\n\nprint(f\"\\nâœ… DataLoaders created!\")\nprint(f\"   Train batches: {len(train_loader)}\")\nprint(f\"   Val batches: {len(val_loader)}\")","metadata":{"execution":{"iopub.status.busy":"2026-02-21T05:14:20.496559Z","iopub.execute_input":"2026-02-21T05:14:20.496858Z","iopub.status.idle":"2026-02-21T05:14:20.547566Z","shell.execute_reply.started":"2026-02-21T05:14:20.496832Z","shell.execute_reply":"2026-02-21T05:14:20.546919Z"},"papermill":{"duration":0.050435,"end_time":"2026-02-03T01:31:48.725164","exception":false,"start_time":"2026-02-03T01:31:48.674729","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"ğŸ‹ï¸ Train samples: 76048\nğŸ§ª Validation samples: 19012\n\nâœ… DataLoaders created!\n   Train batches: 2377\n   Val batches: 595\n","output_type":"stream"}],"execution_count":13},{"id":"73e852fe","cell_type":"markdown","source":"## ğŸ¤– Model Definition - MobileNet V2","metadata":{"papermill":{"duration":0.004377,"end_time":"2026-02-03T01:31:48.734044","exception":false,"start_time":"2026-02-03T01:31:48.729667","status":"completed"},"tags":[]}},{"id":"76421796","cell_type":"code","source":"# â”€â”€ Imports (add to your existing imports) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nfrom torchvision.models import swin_b, Swin_B_Weights\n\n# â”€â”€ Update Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nclass Config:\n    DATA_DIR = \"/kaggle/input\"\n    OUTPUT_DIR = \"/kaggle/working\"\n    \n    MODEL_NAME = \"swin_transformer_base\"\n    NUM_CLASSES = 3\n    LABELS = [\"Cardiomegaly\", \"Edema\", \"Pneumothorax\"]\n    \n    BATCH_SIZE = 16          # Swin-B is heavier, reduce if OOM\n    NUM_EPOCHS = 25\n    LEARNING_RATE = 1e-4\n    WEIGHT_DECAY = 1e-5\n    \n    IMG_SIZE = 224           # Swin-B uses 224x224\n    \n    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    SEED = 42\n\nconfig = Config()\n\n# â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nclass SwinTransformerBaseChestXray(nn.Module):\n    def __init__(self, num_classes=3, pretrained=True):\n        super().__init__()\n        \n        # Load pretrained Swin-B\n        weights = Swin_B_Weights.IMAGENET1K_V1 if pretrained else None\n        self.backbone = swin_b(weights=weights)\n        \n        # Replace the head\n        in_features = self.backbone.head.in_features  # 1024 for Swin-B\n        self.backbone.head = nn.Sequential(\n            nn.Linear(in_features, 512),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(512, num_classes)\n        )\n    \n    def forward(self, x):\n        return self.backbone(x)\n\n# â”€â”€ Instantiate â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nmodel = SwinTransformerBaseChestXray(num_classes=config.NUM_CLASSES, pretrained=True)\nmodel = model.to(config.DEVICE)\n\n# Verify\ntotal_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f\"âœ… Model: Swin Transformer Base\")\nprint(f\"   Total params:     {total_params:,}\")\nprint(f\"   Trainable params: {trainable_params:,}\")","metadata":{"execution":{"iopub.status.busy":"2026-02-21T05:14:20.548922Z","iopub.execute_input":"2026-02-21T05:14:20.549552Z","iopub.status.idle":"2026-02-21T05:14:22.445843Z","shell.execute_reply.started":"2026-02-21T05:14:20.549520Z","shell.execute_reply":"2026-02-21T05:14:22.445144Z"},"papermill":{"duration":0.557042,"end_time":"2026-02-03T01:31:49.295205","exception":false,"start_time":"2026-02-03T01:31:48.738163","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"âœ… Model: Swin Transformer Base\n   Total params:     87,269,563\n   Trainable params: 87,269,563\n","output_type":"stream"}],"execution_count":14},{"id":"780a01db","cell_type":"markdown","source":"## ğŸ¯ Training Setup","metadata":{"papermill":{"duration":0.004138,"end_time":"2026-02-03T01:31:49.303882","exception":false,"start_time":"2026-02-03T01:31:49.299744","status":"completed"},"tags":[]}},{"id":"ce6e2b66","cell_type":"code","source":"# Loss function (BCE for multi-label)\ncriterion = nn.BCEWithLogitsLoss()\n\n# Optimizer\noptimizer = optim.AdamW(\n    model.parameters(), \n    lr=config.LEARNING_RATE, \n    weight_decay=config.WEIGHT_DECAY\n)\n\n# Scheduler\nscheduler = CosineAnnealingLR(optimizer, T_max=config.NUM_EPOCHS, eta_min=1e-6)\n\nprint(\"âœ… Training setup complete!\")\nprint(f\"   Loss: BCEWithLogitsLoss\")\nprint(f\"   Optimizer: AdamW (LR={config.LEARNING_RATE})\")\nprint(f\"   Scheduler: CosineAnnealingLR\")","metadata":{"execution":{"iopub.status.busy":"2026-02-21T05:14:22.446859Z","iopub.execute_input":"2026-02-21T05:14:22.447241Z","iopub.status.idle":"2026-02-21T05:14:22.453155Z","shell.execute_reply.started":"2026-02-21T05:14:22.447213Z","shell.execute_reply":"2026-02-21T05:14:22.452372Z"},"papermill":{"duration":0.012754,"end_time":"2026-02-03T01:31:49.320605","exception":false,"start_time":"2026-02-03T01:31:49.307851","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"âœ… Training setup complete!\n   Loss: BCEWithLogitsLoss\n   Optimizer: AdamW (LR=0.0001)\n   Scheduler: CosineAnnealingLR\n","output_type":"stream"}],"execution_count":15},{"id":"eabfb60c","cell_type":"markdown","source":"## ğŸ”§ Training Functions","metadata":{"papermill":{"duration":0.004148,"end_time":"2026-02-03T01:31:49.328984","exception":false,"start_time":"2026-02-03T01:31:49.324836","status":"completed"},"tags":[]}},{"id":"10644881","cell_type":"code","source":"def train_epoch(model, loader, criterion, optimizer, device):\n    model.train()\n    running_loss = 0.0\n    all_preds = []\n    all_labels = []\n    \n    # Use tqdm for progress bar if loader is not empty\n    if len(loader) > 0:\n        pbar = tqdm(loader, desc=\"Training\")\n        for images, labels in pbar:\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            # Forward pass\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            \n            # Backward pass\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n            \n            # Collect predictions\n            preds = torch.sigmoid(outputs).detach().cpu().numpy()\n            all_preds.extend(preds)\n            all_labels.extend(labels.cpu().numpy())\n            \n            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n        \n        epoch_loss = running_loss / len(loader)\n    else:\n        epoch_loss = 0.0\n    \n    # Calculate accuracy (threshold = 0.5)\n    if len(all_preds) > 0:\n        all_preds = np.array(all_preds)\n        all_labels = np.array(all_labels)\n        binary_preds = (all_preds > 0.5).astype(int)\n        accuracy = (binary_preds == all_labels).mean()\n    else:\n        accuracy = 0.0\n    \n    return epoch_loss, accuracy\n\ndef validate_epoch(model, loader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    all_preds = []\n    all_probs = []\n    all_labels = []\n    \n    with torch.no_grad():\n        if len(loader) > 0:\n            pbar = tqdm(loader, desc=\"Validation\")\n            for images, labels in pbar:\n                images = images.to(device)\n                labels = labels.to(device)\n                \n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                \n                running_loss += loss.item()\n                \n                probs = torch.sigmoid(outputs).cpu().numpy()\n                all_probs.extend(probs)\n                all_preds.extend((probs > 0.5).astype(int))\n                all_labels.extend(labels.cpu().numpy())\n            \n            epoch_loss = running_loss / len(loader)\n        else:\n            epoch_loss = 0.0\n    \n    # Calculate accuracy\n    if len(all_preds) > 0:\n        all_preds = np.array(all_preds)\n        all_labels = np.array(all_labels)\n        all_probs = np.array(all_probs)\n        accuracy = (all_preds == all_labels).mean()\n    else:\n        accuracy = 0.0\n        all_preds, all_labels, all_probs = np.array([]), np.array([]), np.array([])\n    \n    return epoch_loss, accuracy, all_preds, all_probs, all_labels","metadata":{"execution":{"iopub.status.busy":"2026-02-21T05:14:22.453987Z","iopub.execute_input":"2026-02-21T05:14:22.454236Z","iopub.status.idle":"2026-02-21T05:14:22.466765Z","shell.execute_reply.started":"2026-02-21T05:14:22.454208Z","shell.execute_reply":"2026-02-21T05:14:22.466137Z"},"papermill":{"duration":0.01729,"end_time":"2026-02-03T01:31:49.350436","exception":false,"start_time":"2026-02-03T01:31:49.333146","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":16},{"id":"c2664485","cell_type":"markdown","source":"## ğŸ‹ï¸ Training Loop","metadata":{"papermill":{"duration":0.00418,"end_time":"2026-02-03T01:31:49.359016","exception":false,"start_time":"2026-02-03T01:31:49.354836","status":"completed"},"tags":[]}},{"id":"23b52815","cell_type":"code","source":"print(\"=\" * 60)\nprint(\"ğŸš€ TRAINING STARTED - MobileNet V2\")\nprint(\"=\" * 60)\n\nhistory = {\n    'train_loss': [], 'train_acc': [],\n    'val_loss': [], 'val_acc': []\n}\n\nbest_val_loss = float('inf')\nbest_model_state = None\n\n# Check if we have data to train\nif len(train_loader) > 0:\n    for epoch in range(config.NUM_EPOCHS):\n        print(f\"\\nğŸ“… Epoch {epoch+1}/{config.NUM_EPOCHS}\")\n        print(\"-\" * 40)\n        \n        # Train\n        train_loss, train_acc = train_epoch(\n            model, train_loader, criterion, optimizer, config.DEVICE\n        )\n        \n        # Validate\n        val_loss, val_acc, val_preds, val_probs, val_labels = validate_epoch(\n            model, val_loader, criterion, config.DEVICE\n        )\n        \n        # Update scheduler\n        scheduler.step()\n        \n        # Save history\n        history['train_loss'].append(train_loss)\n        history['train_acc'].append(train_acc)\n        history['val_loss'].append(val_loss)\n        history['val_acc'].append(val_acc)\n        \n        # Print metrics\n        print(f\"ğŸ“‰ Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n        print(f\"ğŸ“Š Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n        print(f\"ğŸ“ˆ LR: {scheduler.get_last_lr()[0]:.6f}\")\n        \n        # Save best model\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            best_model_state = model.state_dict().copy()\n            print(\"âœ… Best model saved!\")\n    \n    # Load best model\n    if best_model_state is not None:\n        model.load_state_dict(best_model_state)\n        \n        # Save model\n        model_path = os.path.join(config.OUTPUT_DIR, \"mobilenet_chestxray.pth\")\n        torch.save(best_model_state, model_path)\n        print(f\"\\nğŸ’¾ Model saved to: {model_path}\")\nelse:\n    print(\"âš ï¸ No training data available. Skipping training loop.\")","metadata":{"execution":{"iopub.status.busy":"2026-02-21T05:14:22.467732Z","iopub.execute_input":"2026-02-21T05:14:22.468029Z"},"papermill":{"duration":9202.599361,"end_time":"2026-02-03T04:05:11.962612","exception":false,"start_time":"2026-02-03T01:31:49.363251","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"============================================================\nğŸš€ TRAINING STARTED - MobileNet V2\n============================================================\n\nğŸ“… Epoch 1/25\n----------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2377/2377 [24:55<00:00,  1.59it/s, loss=0.3771]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 595/595 [02:06<00:00,  4.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"ğŸ“‰ Train Loss: 0.4314 | Train Acc: 0.8041\nğŸ“Š Val Loss: 0.3941 | Val Acc: 0.8281\nğŸ“ˆ LR: 0.000100\nâœ… Best model saved!\n\nğŸ“… Epoch 2/25\n----------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2081/2377 [21:49<03:06,  1.59it/s, loss=0.4040]","output_type":"stream"}],"execution_count":null},{"id":"94311c10","cell_type":"markdown","source":"## ğŸ“ˆ Plot Training Curves","metadata":{"papermill":{"duration":5.216244,"end_time":"2026-02-03T04:05:22.328124","exception":false,"start_time":"2026-02-03T04:05:17.111880","status":"completed"},"tags":[]}},{"id":"060344d3","cell_type":"code","source":"if len(history['train_loss']) > 0:\n    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n    # Loss curve\n    axes[0].plot(history['train_loss'], label='Train Loss', marker='o', linewidth=2, color='#e74c3c')\n    axes[0].plot(history['val_loss'], label='Val Loss', marker='s', linewidth=2, color='#3498db')\n    axes[0].set_xlabel('Epoch', fontsize=12)\n    axes[0].set_ylabel('Loss', fontsize=12)\n    axes[0].set_title('ğŸ“‰ Training & Validation Loss', fontsize=14, fontweight='bold')\n    axes[0].legend(fontsize=10)\n    axes[0].grid(True, alpha=0.3)\n\n    # Accuracy curve\n    axes[1].plot(history['train_acc'], label='Train Accuracy', marker='o', linewidth=2, color='#2ecc71')\n    axes[1].plot(history['val_acc'], label='Val Accuracy', marker='s', linewidth=2, color='#9b59b6')\n    axes[1].set_xlabel('Epoch', fontsize=12)\n    axes[1].set_ylabel('Accuracy', fontsize=12)\n    axes[1].set_title('ğŸ“ˆ Training & Validation Accuracy', fontsize=14, fontweight='bold')\n    axes[1].legend(fontsize=10)\n    axes[1].grid(True, alpha=0.3)\n\n    plt.tight_layout()\n    plt.savefig(os.path.join(config.OUTPUT_DIR, 'mobilenet_training_curves.png'), dpi=300, bbox_inches='tight')\n    plt.show()\n    print(\"âœ… Saved: mobilenet_training_curves.png\")\nelse:\n    print(\"âš ï¸ No training history to plot.\")","metadata":{"papermill":{"duration":6.074527,"end_time":"2026-02-03T04:05:33.802198","exception":false,"start_time":"2026-02-03T04:05:27.727671","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"cdf126fe","cell_type":"markdown","source":"## ğŸ” Final Evaluation","metadata":{"papermill":{"duration":5.126787,"end_time":"2026-02-03T04:05:44.106945","exception":false,"start_time":"2026-02-03T04:05:38.980158","status":"completed"},"tags":[]}},{"id":"e39f00d3","cell_type":"code","source":"print(\"=\" * 60)\nprint(\"ğŸ” FINAL EVALUATION\")\nprint(\"=\" * 60)\n\n# Get final predictions\nif len(val_loader) > 0 and best_model_state is not None:\n    val_loss, val_acc, all_preds, all_probs, all_labels = validate_epoch(\n        model, val_loader, criterion, config.DEVICE\n    )\n\n    print(f\"\\nğŸ“Š Final Validation Loss: {val_loss:.4f}\")\n    print(f\"ğŸ“Š Final Validation Accuracy: {val_acc:.4f}\")\nelse:\n    print(\"âš ï¸ Skipping evaluation due to missing data or model.\")\n    all_preds, all_probs, all_labels = [], [], []","metadata":{"papermill":{"duration":53.160975,"end_time":"2026-02-03T04:06:42.654168","exception":false,"start_time":"2026-02-03T04:05:49.493193","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"fb8399a3","cell_type":"markdown","source":"## ğŸ“Š 4 Binary Confusion Matrices","metadata":{"papermill":{"duration":5.125213,"end_time":"2026-02-03T04:06:52.949152","exception":false,"start_time":"2026-02-03T04:06:47.823939","status":"completed"},"tags":[]}},{"id":"f8c641f3","cell_type":"code","source":"if len(all_preds) > 0:\n    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n    # axes is already 1D for 1x3 subplot\n\n    colors = ['Blues', 'Greens', 'Oranges', 'Purples']\n\n    for i, label in enumerate(config.LABELS):\n        # Get binary predictions and labels for this class\n        class_preds = all_preds[:, i]\n        class_labels = all_labels[:, i]\n        \n        # Compute confusion matrix\n        cm = confusion_matrix(class_labels, class_preds)\n        \n        # Plot\n        sns.heatmap(\n            cm, annot=True, fmt='d', cmap=colors[i],\n            xticklabels=['Negative', 'Positive'],\n            yticklabels=['Negative', 'Positive'],\n            ax=axes[i], annot_kws={'size': 16}\n        )\n        axes[i].set_xlabel('Predicted', fontsize=12)\n        axes[i].set_ylabel('Actual', fontsize=12)\n        axes[i].set_title(f'ğŸ·ï¸ {label}\\nConfusion Matrix', fontsize=14, fontweight='bold')\n\n    plt.suptitle(' - Confusion Matrices', fontsize=16, fontweight='bold', y=1.02)\n    plt.tight_layout()\n    plt.savefig(os.path.join(config.OUTPUT_DIR, 'confusion_matrices.png'), dpi=300, bbox_inches='tight')\n    plt.show()\n    print(\"âœ… Saved: econfusion_matrices.png\")","metadata":{"papermill":{"duration":7.243743,"end_time":"2026-02-03T04:07:05.506931","exception":false,"start_time":"2026-02-03T04:06:58.263188","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"4a0ec3fb","cell_type":"markdown","source":"## ğŸ“‹ 4 Binary Classification Reports","metadata":{"papermill":{"duration":5.167192,"end_time":"2026-02-03T04:07:15.831767","exception":false,"start_time":"2026-02-03T04:07:10.664575","status":"completed"},"tags":[]}},{"id":"1f212a6d","cell_type":"code","source":"if len(all_preds) > 0:\n    print(\"=\" * 60)\n    print(\"ğŸ“‹ CLASSIFICATION REPORTS (Binary)\")\n    print(\"=\" * 60)\n\n    reports = []\n\n    for i, label in enumerate(config.LABELS):\n        print(f\"\\n{'='*50}\")\n        print(f\"ğŸ·ï¸ CLASSIFICATION REPORT: {label}\")\n        print('='*50)\n        \n        class_preds = all_preds[:, i]\n        class_labels = all_labels[:, i]\n        \n        # Print detailed report\n        report = classification_report(\n            class_labels, class_preds, \n            target_names=['Negative', 'Positive'],\n            digits=4\n        )\n        print(report)\n        \n        # Calculate individual metrics\n        acc = accuracy_score(class_labels, class_preds)\n        precision = precision_score(class_labels, class_preds, zero_division=0)\n        recall = recall_score(class_labels, class_preds, zero_division=0)\n        f1 = f1_score(class_labels, class_preds, zero_division=0)\n        \n        reports.append({\n            'Label': label,\n            'Accuracy': acc,\n            'Precision': precision,\n            'Recall': recall,\n            'F1-Score': f1\n        })\n\n    # Create summary table\n    reports_df = pd.DataFrame(reports)\n    print(\"\\n\" + \"=\" * 60)\n    print(\"ğŸ“Š SUMMARY TABLE\")\n    print(\"=\" * 60)\n    print(reports_df.to_string(index=False))\n\n    # Save reports to CSV\n    reports_df.to_csv(os.path.join(config.OUTPUT_DIR, 'mobilenet_classification_reports.csv'), index=False)\n    print(\"\\nâœ… Saved: mobilenet_classification_reports.csv\")","metadata":{"papermill":{"duration":5.462622,"end_time":"2026-02-03T04:07:26.434387","exception":false,"start_time":"2026-02-03T04:07:20.971765","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"d644964d","cell_type":"markdown","source":"## ğŸ“Š Metrics Comparison Chart","metadata":{"papermill":{"duration":5.138778,"end_time":"2026-02-03T04:07:36.669611","exception":false,"start_time":"2026-02-03T04:07:31.530833","status":"completed"},"tags":[]}},{"id":"afce2971","cell_type":"code","source":"if len(all_preds) > 0:\n    fig, ax = plt.subplots(figsize=(12, 6))\n\n    x = np.arange(len(config.LABELS))\n    width = 0.2\n\n    bars1 = ax.bar(x - 1.5*width, reports_df['Accuracy'], width, label='Accuracy', color='#2ecc71')\n    bars2 = ax.bar(x - 0.5*width, reports_df['Precision'], width, label='Precision', color='#3498db')\n    bars3 = ax.bar(x + 0.5*width, reports_df['Recall'], width, label='Recall', color='#e74c3c')\n    bars4 = ax.bar(x + 1.5*width, reports_df['F1-Score'], width, label='F1-Score', color='#9b59b6')\n\n    ax.set_xlabel('Class', fontsize=12)\n    ax.set_ylabel('Score', fontsize=12)\n    ax.set_title('ğŸ“Š Binary Classification Metrics - MobileNet V2', fontsize=14, fontweight='bold')\n    ax.set_xticks(x)\n    ax.set_xticklabels(config.LABELS, fontsize=11)\n    ax.legend(fontsize=10)\n    ax.set_ylim(0, 1.05)\n    ax.grid(True, alpha=0.3, axis='y')\n\n    # Add value labels on bars\n    for bars in [bars1, bars2, bars3, bars4]:\n        for bar in bars:\n            height = bar.get_height()\n            ax.annotate(f'{height:.2f}',\n                        xy=(bar.get_x() + bar.get_width() / 2, height),\n                        xytext=(0, 3),\n                        textcoords=\"offset points\",\n                        ha='center', va='bottom', fontsize=8)\n\n    plt.tight_layout()\n    plt.savefig(os.path.join(config.OUTPUT_DIR, 'mobilenet_metrics_comparison.png'), dpi=300, bbox_inches='tight')\n    plt.show()\n    print(\"âœ… Saved: mobilenet_metrics_comparison.png\")","metadata":{"papermill":{"duration":6.023288,"end_time":"2026-02-03T04:07:47.847314","exception":false,"start_time":"2026-02-03T04:07:41.824026","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"4472755c","cell_type":"markdown","source":"## ğŸ“ˆ ROC Curves for All 4 Classes","metadata":{"papermill":{"duration":5.320792,"end_time":"2026-02-03T04:07:58.253301","exception":false,"start_time":"2026-02-03T04:07:52.932509","status":"completed"},"tags":[]}},{"id":"bc84b4e4","cell_type":"code","source":"if len(all_preds) > 0:\n    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n    # axes is already 1D for 1x3 subplot\n\n    colors = ['#e74c3c', '#3498db', '#2ecc71']\n\n    for i, label in enumerate(config.LABELS):\n        class_probs = all_probs[:, i]\n        class_labels = all_labels[:, i]\n        \n        # Compute ROC curve\n        fpr, tpr, _ = roc_curve(class_labels, class_probs)\n        roc_auc = auc(fpr, tpr)\n        \n        # Plot\n        axes[i].plot(fpr, tpr, color=colors[i], linewidth=2, \n                     label=f'ROC curve (AUC = {roc_auc:.4f})')\n        axes[i].plot([0, 1], [0, 1], 'k--', linewidth=1, alpha=0.5)\n        axes[i].fill_between(fpr, tpr, alpha=0.2, color=colors[i])\n        axes[i].set_xlim([0.0, 1.0])\n        axes[i].set_ylim([0.0, 1.05])\n        axes[i].set_xlabel('False Positive Rate', fontsize=12)\n        axes[i].set_ylabel('True Positive Rate', fontsize=12)\n        axes[i].set_title(f'ğŸ·ï¸ {label}\\nROC Curve', fontsize=14, fontweight='bold')\n        axes[i].legend(loc='lower right', fontsize=11)\n        axes[i].grid(True, alpha=0.3)\n\n    plt.suptitle(' ROC Curves', fontsize=16, fontweight='bold', y=1.02)\n    plt.tight_layout()\n    plt.savefig(os.path.join(config.OUTPUT_DIR, 'efficientnet_roc_curves.png'), dpi=300, bbox_inches='tight')\n    plt.show()\n   ","metadata":{"papermill":{"duration":7.378035,"end_time":"2026-02-03T04:08:10.588041","exception":false,"start_time":"2026-02-03T04:08:03.210006","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"e937a756","cell_type":"markdown","source":"## ğŸ‰ Final Summary","metadata":{"papermill":{"duration":5.188234,"end_time":"2026-02-03T04:08:20.900909","exception":false,"start_time":"2026-02-03T04:08:15.712675","status":"completed"},"tags":[]}},{"id":"dfa3e2cc","cell_type":"code","source":"print(\"=\" * 60)\nprint(\"ğŸ‰ TRAINING COMPLETE! - MobileNet V2\")\nprint(\"=\" * 60)\n\nif len(all_preds) > 0:\n    print(f\"\"\"\n    ğŸ¤– Model: MobileNet V2\n    ğŸ“Š Dataset: CheXpert (4-class: {', '.join(config.LABELS)})\n    ğŸ‹ï¸ Training samples: {len(train_df)}\n    ğŸ§ª Validation samples: {len(val_df)}\n\n    ğŸ“‰ Best Validation Loss: {best_val_loss:.4f}\n    ğŸ“ˆ Final Validation Accuracy: {val_acc:.4f}\n\n    ğŸ“ Output Files:\n      ğŸ“Š mobilenet_training_curves.png\n      ğŸ“Š mobilenet_confusion_matrices.png\n      ğŸ“Š mobilenet_metrics_comparison.png\n      ğŸ“Š mobilenet_roc_curves.png\n      ğŸ“„ mobilenet_classification_reports.csv\n      ğŸ”§ mobilenet_chestxray.pth\n\n    ğŸ“‹ Per-Class Performance:\n    \"\"\")\n\n    for _, row in reports_df.iterrows():\n        print(f\"  {row['Label']}: Acc={row['Accuracy']:.4f} | F1={row['F1-Score']:.4f}\")\n\n    print(\"\\nâœ… All outputs saved successfully!\")\nelse:\n    print(\"âš ï¸ No results to report.\")","metadata":{"papermill":{"duration":5.376516,"end_time":"2026-02-03T04:08:31.418870","exception":false,"start_time":"2026-02-03T04:08:26.042354","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}